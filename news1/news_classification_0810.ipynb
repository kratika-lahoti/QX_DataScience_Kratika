{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd # CSV file I/O (pd.read_csv)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adani Ports Shares Jump Nearly 6% as Buyback O...</td>\n",
       "      <td>August 26, 2019, 4:25 PM IST\\nFor Representati...</td>\n",
       "      <td>Buyback of shares - Alert me when any of these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adani Ports buyback to open on September 6; sh...</td>\n",
       "      <td>Adani Ports and Special Economic Zone\\ngained ...</td>\n",
       "      <td>Buyback of shares - Alert me when any of these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adani Ports Q1 net profit jumps 47.50%</td>\n",
       "      <td>Adani Ports and Special Economic Zone (APSEZ) ...</td>\n",
       "      <td>Earnings, Stock Performance or Dividends - Ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adani Ports keen on building port at Nagarjuna...</td>\n",
       "      <td>Adani Ports and Special Economic Zone Ltd (APS...</td>\n",
       "      <td>New Geography - Alert me when a company moves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adani Ports Q1 result: Adani Ports Q1 PAT jump...</td>\n",
       "      <td>Adani Ports\\non Wednesday said its consolidate...</td>\n",
       "      <td>Earnings, Stock Performance or Dividends - Ale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Adani Ports Shares Jump Nearly 6% as Buyback O...   \n",
       "1  Adani Ports buyback to open on September 6; sh...   \n",
       "2             Adani Ports Q1 net profit jumps 47.50%   \n",
       "3  Adani Ports keen on building port at Nagarjuna...   \n",
       "4  Adani Ports Q1 result: Adani Ports Q1 PAT jump...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  August 26, 2019, 4:25 PM IST\\nFor Representati...   \n",
       "1  Adani Ports and Special Economic Zone\\ngained ...   \n",
       "2  Adani Ports and Special Economic Zone (APSEZ) ...   \n",
       "3  Adani Ports and Special Economic Zone Ltd (APS...   \n",
       "4  Adani Ports\\non Wednesday said its consolidate...   \n",
       "\n",
       "                                            Category  \n",
       "0  Buyback of shares - Alert me when any of these...  \n",
       "1  Buyback of shares - Alert me when any of these...  \n",
       "2  Earnings, Stock Performance or Dividends - Ale...  \n",
       "3  New Geography - Alert me when a company moves ...  \n",
       "4  Earnings, Stock Performance or Dividends - Ale...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_excel(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\News data (Completed) (1) (9).xlsx\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(data) \n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "    \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words_Body = news['Body'].apply(remove_stop_words) \n",
    "#remove_stop_words_Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data\n",
      "Training:  2398\n",
      "Developement:  49\n",
      "Testing:  50\n"
     ]
    }
   ],
   "source": [
    "# ## Split data\n",
    "print(\"\\nSplitting data\")\n",
    "title_tr, title_te, category_tr, category_te = train_test_split(remove_stop_words_Body, news.Category,test_size =.02)\n",
    "title_tr, title_de, category_tr, category_de = train_test_split(title_tr,category_tr,test_size =.02)\n",
    "print(\"Training: \",len(title_tr))\n",
    "print(\"Developement: \",len(title_de),)\n",
    "print(\"Testing: \",len(title_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Data Preprocessing\n",
    "# ## Vectorization of data\n",
    "# Vectorize the data using Bag of words (BOW)\n",
    "print(\"\\nVectorizing data\")\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)\n",
    "\n",
    "vectorizer.fit(iter(title_tr))\n",
    "Xtr = vectorizer.transform(iter(title_tr))\n",
    "Xde = vectorizer.transform(iter(title_de))\n",
    "Xte = vectorizer.transform(iter(title_te))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(category_tr)\n",
    "Ytr = encoder.transform(category_tr)\n",
    "Yde = encoder.transform(category_de)\n",
    "Yte = encoder.transform(category_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applyting Feature Reduction\n",
      "Number of features before reduction :  16601\n",
      "Number of features after reduction :  7379\n"
     ]
    }
   ],
   "source": [
    "# ## Feature Reduction\n",
    "# We can check the variance of the feature and drop them based on a threshold\n",
    "print(\"\\nApplyting Feature Reduction\")\n",
    "print(\"Number of features before reduction : \", Xtr.shape[1])\n",
    "selection = VarianceThreshold(threshold=0.001)\n",
    "Xtr_whole = copy.deepcopy(Xtr)\n",
    "Ytr_whole = copy.deepcopy(Ytr)\n",
    "selection.fit(Xtr)\n",
    "Xtr = selection.transform(Xtr)\n",
    "Xde = selection.transform(Xde)\n",
    "Xte = selection.transform(Xte)\n",
    "print(\"Number of features after reduction : \", Xtr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training baseline classifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Train Models\n",
    "# ### Baseline Model\n",
    "# “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "print(\"\\n\\nTraining baseline classifier\")\n",
    "dc = DummyClassifier(strategy=\"stratified\")\n",
    "dc.fit(Xtr, Ytr)\n",
    "pred = dc.predict(Xde)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "          10       0.12      0.12      0.12         8\n",
      "          16       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.33      0.20      0.25         5\n",
      "          40       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         2\n",
      "          54       0.50      0.33      0.40         3\n",
      "          55       0.00      0.00      0.00         0\n",
      "          59       0.38      0.38      0.38        13\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.16        49\n",
      "   macro avg       0.05      0.04      0.04        49\n",
      "weighted avg       0.19      0.16      0.17        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Yde, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
