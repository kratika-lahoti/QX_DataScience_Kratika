{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Category</th>\n",
       "      <th>MegaCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BS-VI transition may lead to dumping of old st...</td>\n",
       "      <td>BS-VI transition may lead to dumping of old st...</td>\n",
       "      <td>Annual Report - Comments made in the Annual Re...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual Report 2016-2017 of Bajaj Finserv Limited</td>\n",
       "      <td>It is a broadly described annual report of Baj...</td>\n",
       "      <td>Annual Report - Comments made in the Annual Re...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annual Report 2017-2018 of Eicher Motors Limit...</td>\n",
       "      <td>It is a broadly described annual report of\\nEi...</td>\n",
       "      <td>Annual Report - Comments made in the Annual Re...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindalco Industries : Chairman Kumar Mangalam ...</td>\n",
       "      <td>(You can enter multiple email addresses separa...</td>\n",
       "      <td>Annual Report - Comments made in the Annual Re...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WIPRO continues it's uptrend, although on a we...</td>\n",
       "      <td>WIPRO continues it's uptrend, although on a we...</td>\n",
       "      <td>Annual Report - Comments made in the Annual Re...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  BS-VI transition may lead to dumping of old st...   \n",
       "1   Annual Report 2016-2017 of Bajaj Finserv Limited   \n",
       "2  Annual Report 2017-2018 of Eicher Motors Limit...   \n",
       "3  Hindalco Industries : Chairman Kumar Mangalam ...   \n",
       "4  WIPRO continues it's uptrend, although on a we...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  BS-VI transition may lead to dumping of old st...   \n",
       "1  It is a broadly described annual report of Baj...   \n",
       "2  It is a broadly described annual report of\\nEi...   \n",
       "3  (You can enter multiple email addresses separa...   \n",
       "4  WIPRO continues it's uptrend, although on a we...   \n",
       "\n",
       "                                            Category MegaCategory  \n",
       "0  Annual Report - Comments made in the Annual Re...    Financial  \n",
       "1  Annual Report - Comments made in the Annual Re...    Financial  \n",
       "2  Annual Report - Comments made in the Annual Re...    Financial  \n",
       "3  Annual Report - Comments made in the Annual Re...    Financial  \n",
       "4  Annual Report - Comments made in the Annual Re...    Financial  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_excel(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\News333.xlsx\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.union(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    stop_words.union(['jan','feb','mar','apr','may','jun','jul','aug','sept','oct','nov','dec'])\n",
    "    stop_words.union(['monday', 'tuesday', 'wednesday', 'thursday','friday','saturday','sunday'])\n",
    "    stop_words.union(['am', 'pm'])\n",
    "    word_tokens = word_tokenize(data) \n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w.lower() not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "    \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['text'] = news.Title + \" \" + news.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news['clean_title'] = news['Title'].apply(remove_stop_words)\n",
    "news['clean_body'] = news['Body'].apply(remove_stop_words)\n",
    "\n",
    "news['clean_text'] = news['text'].apply(remove_stop_words) \n",
    "\n",
    "#remove_stop_words_Body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data\n",
      "Training:  2007\n",
      "Developement:  223\n",
      "Testing:  248\n"
     ]
    }
   ],
   "source": [
    "# ## Split data\n",
    "print(\"\\nSplitting data\")\n",
    "\n",
    "title_tr, title_te, MegaCategory_tr, MegaCategory_te = train_test_split(news['clean_text'], news.MegaCategory,test_size =.1)\n",
    "title_tr, title_de, MegaCategory_tr , MegaCategory_de = train_test_split(title_tr,MegaCategory_tr,test_size =.1)\n",
    "\n",
    "\n",
    "print(\"Training: \",len(title_tr))\n",
    "print(\"Developement: \",len(title_de),)\n",
    "print(\"Testing: \",len(title_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Data Preprocessing\n",
    "# ## Vectorization of data\n",
    "# Vectorize the data using Bag of words (BOW)\n",
    "print(\"\\nVectorizing data\")\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)\n",
    "\n",
    "vectorizer.fit(iter(title_tr))\n",
    "Xtr = vectorizer.transform(iter(title_tr))\n",
    "Xde = vectorizer.transform(iter(title_de))\n",
    "Xte = vectorizer.transform(iter(title_te))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(MegaCategory_tr)\n",
    "Ytr = encoder.transform(MegaCategory_tr)\n",
    "Yde = encoder.transform(MegaCategory_de)\n",
    "Yte = encoder.transform(MegaCategory_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11  8 ... 11  5 11]\n"
     ]
    }
   ],
   "source": [
    "print(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2007x15905 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 103928 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training baseline classifier\n"
     ]
    }
   ],
   "source": [
    "# # Train Models\n",
    "# ### Baseline Model\n",
    "# “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "print(\"\\n\\nTraining baseline classifier\")\n",
    "dc = DummyClassifier(strategy=\"stratified\")\n",
    "dc.fit(Xtr, Ytr)\n",
    "dc_pred = dc.predict(Xde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.36      0.38      0.37        79\n",
      "   Corporate Updates       0.36      0.38      0.37        79\n",
      "               Event       0.00      0.00      0.00        23\n",
      "              Events       0.08      0.09      0.08        35\n",
      "           Financial       0.00      0.00      0.00        23\n",
      "              Growth       0.36      0.38      0.37        79\n",
      "       Industry News       0.36      0.38      0.37        79\n",
      "         Market Buzz       0.08      0.09      0.08        35\n",
      "       Negative News       0.17      0.17      0.17        24\n",
      "              People       0.17      0.17      0.17        24\n",
      "   Stock Performance       0.36      0.38      0.37        79\n",
      "  Uncategorised News       0.36      0.38      0.37        79\n",
      "\n",
      "           micro avg       0.28      0.30      0.29     95839\n",
      "           macro avg       0.20      0.21      0.21     95839\n",
      "        weighted avg       0.28      0.30      0.29     95839\n",
      "\n",
      "Accuracy achieved is 0.19282511210762332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Yde, dc_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(dc_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision tree\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.57      0.73      0.64        79\n",
      "   Corporate Updates       0.57      0.73      0.64        79\n",
      "               Event       0.55      0.26      0.35        23\n",
      "              Events       0.58      0.60      0.59        35\n",
      "           Financial       0.55      0.26      0.35        23\n",
      "              Growth       0.57      0.73      0.64        79\n",
      "       Industry News       0.57      0.73      0.64        79\n",
      "         Market Buzz       0.58      0.60      0.59        35\n",
      "       Negative News       0.22      0.29      0.25        24\n",
      "              People       0.22      0.29      0.25        24\n",
      "   Stock Performance       0.57      0.73      0.64        79\n",
      "  Uncategorised News       0.57      0.73      0.64        79\n",
      "\n",
      "           micro avg       0.55      0.64      0.59     95839\n",
      "           macro avg       0.49      0.52      0.50     95839\n",
      "        weighted avg       0.54      0.64      0.58     95839\n",
      "\n",
      "Accuracy achieved is 0.5022421524663677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Decision Tree\n",
    "print(\"Training Decision tree\")\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(Xtr, Ytr)\n",
    "dt_pred = dt.predict(Xde)\n",
    "print(classification_report(Yde, dt_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(dt_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.56      0.92      0.70        79\n",
      "   Corporate Updates       0.56      0.92      0.70        79\n",
      "               Event       1.00      0.35      0.52        23\n",
      "              Events       0.66      0.71      0.68        35\n",
      "           Financial       1.00      0.35      0.52        23\n",
      "              Growth       0.56      0.92      0.70        79\n",
      "       Industry News       0.56      0.92      0.70        79\n",
      "         Market Buzz       0.66      0.71      0.68        35\n",
      "       Negative News       0.65      0.46      0.54        24\n",
      "              People       0.65      0.46      0.54        24\n",
      "   Stock Performance       0.56      0.92      0.70        79\n",
      "  Uncategorised News       0.56      0.92      0.70        79\n",
      "\n",
      "           micro avg       0.58      0.80      0.67     95839\n",
      "           macro avg       0.63      0.65      0.59     95839\n",
      "        weighted avg       0.60      0.80      0.66     95839\n",
      "\n",
      "Accuracy achieved is 0.6143497757847534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ### Random Forest\n",
    "print(\"Training Random Forest\")\n",
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(Xtr, Ytr)\n",
    "pred = rf.predict(Xde)\n",
    "print(classification_report(Yde, pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multinomial Naive Bayesian\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.67      0.81      0.73        79\n",
      "   Corporate Updates       0.67      0.81      0.73        79\n",
      "               Event       0.65      0.48      0.55        23\n",
      "              Events       0.59      0.91      0.72        35\n",
      "           Financial       0.65      0.48      0.55        23\n",
      "              Growth       0.67      0.81      0.73        79\n",
      "       Industry News       0.67      0.81      0.73        79\n",
      "         Market Buzz       0.59      0.91      0.72        35\n",
      "       Negative News       0.60      0.62      0.61        24\n",
      "              People       0.60      0.62      0.61        24\n",
      "   Stock Performance       0.67      0.81      0.73        79\n",
      "  Uncategorised News       0.67      0.81      0.73        79\n",
      "\n",
      "           micro avg       0.66      0.77      0.71     95839\n",
      "           macro avg       0.69      0.69      0.65     95839\n",
      "        weighted avg       0.67      0.77      0.71     95839\n",
      "\n",
      "Accuracy achieved is 0.6636771300448431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Multinomial Naive Bayesian\n",
    "print(\"Training Multinomial Naive Bayesian\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtr, Ytr)\n",
    "pred_nb = nb.predict(Xde)\n",
    "print(classification_report(Yde, pred_nb, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_nb == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Support Vector Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.36      0.99      0.53        79\n",
      "   Corporate Updates       0.36      0.99      0.53        79\n",
      "               Event       0.00      0.00      0.00        23\n",
      "              Events       0.62      0.14      0.23        35\n",
      "           Financial       0.00      0.00      0.00        23\n",
      "              Growth       0.36      0.99      0.53        79\n",
      "       Industry News       0.36      0.99      0.53        79\n",
      "         Market Buzz       0.62      0.14      0.23        35\n",
      "       Negative News       0.00      0.00      0.00        24\n",
      "              People       0.00      0.00      0.00        24\n",
      "   Stock Performance       0.36      0.99      0.53        79\n",
      "  Uncategorised News       0.36      0.99      0.53        79\n",
      "\n",
      "           micro avg       0.37      0.71      0.48     95839\n",
      "           macro avg       0.25      0.44      0.26     95839\n",
      "        weighted avg       0.32      0.71      0.40     95839\n",
      "\n",
      "Accuracy achieved is 0.3721973094170404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ### Support Vector Classification\n",
    "print(\"Training Support Vector Classification\")\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(Xtr, Ytr)\n",
    "svc_pred = svc.predict(Xde)\n",
    "print(classification_report(Yde, svc_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(svc_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multilayered Perceptron\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.77      0.85      0.81        79\n",
      "   Corporate Updates       0.77      0.85      0.81        79\n",
      "               Event       0.59      0.57      0.58        23\n",
      "              Events       0.71      0.77      0.74        35\n",
      "           Financial       0.59      0.57      0.58        23\n",
      "              Growth       0.77      0.85      0.81        79\n",
      "       Industry News       0.77      0.85      0.81        79\n",
      "         Market Buzz       0.71      0.77      0.74        35\n",
      "       Negative News       0.56      0.62      0.59        24\n",
      "              People       0.56      0.62      0.59        24\n",
      "   Stock Performance       0.77      0.85      0.81        79\n",
      "  Uncategorised News       0.77      0.85      0.81        79\n",
      "\n",
      "           micro avg       0.74      0.80      0.77     95839\n",
      "           macro avg       0.71      0.73      0.71     95839\n",
      "        weighted avg       0.75      0.80      0.77     95839\n",
      "\n",
      "Accuracy achieved is 0.7085201793721974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 2007, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ### Multilayered Perceptron\n",
    "print(\"Training Multilayered Perceptron\")\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 20), random_state=1, max_iter=400)\n",
    "mlp.fit(Xtr, Ytr)\n",
    "mlp_pred = mlp.predict(Xde)\n",
    "print(classification_report(Yde, mlp_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved is 0.19282511210762332\n",
      "Accuracy achieved is 0.5022421524663677\n",
      "Accuracy achieved is 0.6636771300448431\n",
      "Accuracy achieved is 0.3721973094170404\n",
      "Accuracy achieved is 0.7085201793721974\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy achieved is ' + str(np.mean(dc_pred   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(dt_pred   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_nb   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(svc_pred  == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred  == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predicting test data using Multilayered Perceptron\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Awards & Recognition       0.73      0.86      0.79        95\n",
      "   Corporate Updates       0.73      0.86      0.79        95\n",
      "               Event       0.50      0.42      0.46        26\n",
      "              Events       0.76      0.66      0.70        38\n",
      "           Financial       0.50      0.42      0.46        26\n",
      "              Growth       0.73      0.86      0.79        95\n",
      "       Industry News       0.73      0.86      0.79        95\n",
      "         Market Buzz       0.76      0.66      0.70        38\n",
      "       Negative News       0.58      0.58      0.58        26\n",
      "              People       0.58      0.58      0.58        26\n",
      "   Stock Performance       0.73      0.86      0.79        95\n",
      "  Uncategorised News       0.73      0.86      0.79        95\n",
      "\n",
      "           micro avg       0.71      0.78      0.74    112183\n",
      "           macro avg       0.65      0.67      0.65    112183\n",
      "        weighted avg       0.70      0.78      0.74    112183\n",
      "\n",
      "Accuracy achieved is 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "# # Final Model: Multilayered Perceptron\n",
    "# ## Predict test data\n",
    "print(\"\\n\\nPredicting test data using Multilayered Perceptron\")\n",
    "pred_final = mlp.predict(Xte)\n",
    "print(classification_report(Yte, pred_final, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(accuracy_score(Yte,pred_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\"title\":vectorizer.inverse_transform(Xte), \"predicted\":encoder.inverse_transform(pred_final),\"actual\": encoder.inverse_transform(Yte)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(output, columns=[\"title\",\"predicted\",\"actual\"])\n",
    "#df.to_csv(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\News333_title_predication_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved is 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "pred_final = mlp.predict(Xte)\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_final == Yte)))\n",
    "output = {\"text\":vectorizer.inverse_transform(Xte), \"predicted\":encoder.inverse_transform(pred_final),\"actual\": encoder.inverse_transform(Yte)}\n",
    "df = pd.DataFrame(output, columns=[\"text\",\"predicted\",\"actual\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(output, columns=[\"text\",\"predicted\",\"actual\"])\n",
    "#df.to_csv(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\News333_title_body_predication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
