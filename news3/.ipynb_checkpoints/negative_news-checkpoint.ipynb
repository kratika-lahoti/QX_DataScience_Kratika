{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Category</th>\n",
       "      <th>Old MegaCategory</th>\n",
       "      <th>MegaCategory</th>\n",
       "      <th>important</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Massive fire breaks out at Asian Paints manufa...</td>\n",
       "      <td>Click here to know more.</td>\n",
       "      <td>Black Swan Events - Alert me when a company fa...</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Major Loss for the Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPCL refinery fire doused but tension continue...</td>\n",
       "      <td>BPCL is in the process of setting up a committ...</td>\n",
       "      <td>Black Swan Events - Alert me when a company fa...</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Major Loss for the Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPCL blaze extinguished; sleepless night for l...</td>\n",
       "      <td>Mumbai: The fire at the Mahul refinery of the ...</td>\n",
       "      <td>Black Swan Events - Alert me when a company fa...</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Major Loss for the Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explosion in BPCL plant in Chembur; 43 injured</td>\n",
       "      <td>There was a major explosion on Wednesday in th...</td>\n",
       "      <td>Black Swan Events - Alert me when a company fa...</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Major Loss for the Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45 injured as fire breaks out at BPCL refinery...</td>\n",
       "      <td>The fire was brought under control after three...</td>\n",
       "      <td>Black Swan Events - Alert me when a company fa...</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Negative News</td>\n",
       "      <td>Major Loss for the Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Massive fire breaks out at Asian Paints manufa...   \n",
       "1  BPCL refinery fire doused but tension continue...   \n",
       "2  BPCL blaze extinguished; sleepless night for l...   \n",
       "3     Explosion in BPCL plant in Chembur; 43 injured   \n",
       "4  45 injured as fire breaks out at BPCL refinery...   \n",
       "\n",
       "                                                Body  \\\n",
       "0                           Click here to know more.   \n",
       "1  BPCL is in the process of setting up a committ...   \n",
       "2  Mumbai: The fire at the Mahul refinery of the ...   \n",
       "3  There was a major explosion on Wednesday in th...   \n",
       "4  The fire was brought under control after three...   \n",
       "\n",
       "                                            Category Old MegaCategory  \\\n",
       "0  Black Swan Events - Alert me when a company fa...    Negative News   \n",
       "1  Black Swan Events - Alert me when a company fa...    Negative News   \n",
       "2  Black Swan Events - Alert me when a company fa...    Negative News   \n",
       "3  Black Swan Events - Alert me when a company fa...    Negative News   \n",
       "4  Black Swan Events - Alert me when a company fa...    Negative News   \n",
       "\n",
       "    MegaCategory                   important  \n",
       "0  Negative News  Major Loss for the Company  \n",
       "1  Negative News  Major Loss for the Company  \n",
       "2  Negative News  Major Loss for the Company  \n",
       "3  Negative News  Major Loss for the Company  \n",
       "4  Negative News  Major Loss for the Company  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_excel(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\Negative_News.xlsx\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.union(['january','february','march','april','may','june','july','august','september','october','november','december'])\n",
    "    stop_words.union(['jan','feb','mar','apr','may','jun','jul','aug','sept','oct','nov','dec'])\n",
    "    stop_words.union(['monday', 'tuesday', 'wednesday', 'thursday','friday','saturday','sunday'])\n",
    "    stop_words.union(['am', 'pm'])\n",
    "    word_tokens = word_tokenize(data) \n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w.lower() not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "    \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['text'] = news.Title + \" \" + news.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shareholders : shareholder\n",
      "stocks : stock\n",
      "companys : company\n",
      "trading : trade\n",
      "weekly : week\n",
      "billion: billionaire\n",
      "high : higher\n",
      "close : closeed\n",
      "finance : financial\n",
      "biggest: high\n",
      "unit: unit\n",
      "protect: protection\n",
      "organisation: organised\n",
      "'company: 'companies\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# import these modules \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"shareholders :\", lemmatizer.lemmatize(\"shareholder\")) \n",
    "print(\"stocks :\", lemmatizer.lemmatize(\"stock\")) \n",
    "print(\"companys :\", lemmatizer.lemmatize(\"company\")) \n",
    "print(\"trading :\", lemmatizer.lemmatize(\"trade\")) \n",
    "print(\"weekly :\", lemmatizer.lemmatize(\"week\")) \n",
    "print(\"billion:\", lemmatizer.lemmatize(\"billionaire\")) \n",
    "print(\"high :\", lemmatizer.lemmatize(\"higher\")) \n",
    "print(\"close :\", lemmatizer.lemmatize(\"closeed\")) \n",
    "print(\"finance :\", lemmatizer.lemmatize(\"financial\")) \n",
    "print(\"biggest:\", lemmatizer.lemmatize(\"high\")) \n",
    "print(\"unit:\", lemmatizer.lemmatize(\"units\")) \n",
    "print(\"protect:\", lemmatizer.lemmatize(\"protection\")) \n",
    "print(\"organisation:\", lemmatizer.lemmatize(\"organised\")) \n",
    "print(\"'company:\", lemmatizer.lemmatize(\"'companies\")) \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shareholders : shareholder\n",
      "stocks : stock\n",
      "companys : company\n",
      "trading : trade\n",
      "weekly : week\n",
      "billion: billionaire\n",
      "high : higher\n",
      "close : closeed\n",
      "finance : financial\n",
      "biggest: high\n",
      "unit: unit\n",
      "protect: protection\n",
      "organisation: organised\n",
      "'company: 'companies\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# import these modules \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"shareholders :\", lemmatizer.lemmatize(\"shareholder\")) \n",
    "print(\"stocks :\", lemmatizer.lemmatize(\"stock\")) \n",
    "print(\"companys :\", lemmatizer.lemmatize(\"company\")) \n",
    "print(\"trading :\", lemmatizer.lemmatize(\"trade\")) \n",
    "print(\"weekly :\", lemmatizer.lemmatize(\"week\")) \n",
    "print(\"billion:\", lemmatizer.lemmatize(\"billionaire\")) \n",
    "print(\"high :\", lemmatizer.lemmatize(\"higher\")) \n",
    "print(\"close :\", lemmatizer.lemmatize(\"closeed\")) \n",
    "print(\"finance :\", lemmatizer.lemmatize(\"financial\")) \n",
    "print(\"biggest:\", lemmatizer.lemmatize(\"high\")) \n",
    "print(\"unit:\", lemmatizer.lemmatize(\"units\")) \n",
    "print(\"protect:\", lemmatizer.lemmatize(\"protection\")) \n",
    "print(\"organisation:\", lemmatizer.lemmatize(\"organised\")) \n",
    "print(\"'company:\", lemmatizer.lemmatize(\"'companies\")) \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " news['text']=news['text'].apply(lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news['clean_title'] = news['Title'].apply(remove_stop_words)\n",
    "news['clean_body'] = news['Body'].apply(remove_stop_words)\n",
    "\n",
    "news['clean_text'] = news['text'].apply(remove_stop_words) \n",
    "\n",
    "#remove_stop_words_Body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data\n",
      "Training:  175\n",
      "Testing:  22\n"
     ]
    }
   ],
   "source": [
    "# ## Split data\n",
    "print(\"\\nSplitting data\")\n",
    "\n",
    "title_tr, title_te, MegaCategory_tr, MegaCategory_te = train_test_split(news['clean_text'], news.important,test_size =.1)\n",
    "title_tr, title_de, MegaCategory_tr , MegaCategory_de = train_test_split(title_tr,MegaCategory_tr,test_size =.1)\n",
    "\n",
    "\n",
    "print(\"Training: \",len(title_tr))\n",
    "\n",
    "print(\"Testing: \",len(title_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Data Preprocessing\n",
    "# ## Vectorization of data\n",
    "# Vectorize the data using Bag of words (BOW)\n",
    "print(\"\\nVectorizing data\")\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)\n",
    "\n",
    "vectorizer.fit(iter(title_tr))\n",
    "Xtr = vectorizer.transform(iter(title_tr))\n",
    "Xde = vectorizer.transform(iter(title_de))\n",
    "Xte = vectorizer.transform(iter(title_te))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(MegaCategory_tr)\n",
    "Ytr = encoder.transform(MegaCategory_tr)\n",
    "Yde = encoder.transform(MegaCategory_de)\n",
    "Yte = encoder.transform(MegaCategory_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 2 4 2 3 2 4 2 2 0 3 3 4 1 0 2 0 2 2 2 2 4 3 2 3 2 1 2 2 3 1 1 3 2 4 4\n",
      " 4 0 0 4 2 3 0 4 4 4 4 4 0 1 3 3 3 4 4 1 2 2 3 2 3 3 4 4 4 2 1 2 4 0 3 0 0\n",
      " 2 4 1 0 4 1 1 2 4 3 3 4 2 3 2 3 0 4 3 2 0 1 3 2 3 1 1 4 4 1 4 3 4 3 0 3 4\n",
      " 4 3 1 4 2 0 2 4 0 1 4 3 2 1 4 3 0 4 3 4 4 1 2 3 1 0 0 2 2 3 2 0 3 2 2 2 1\n",
      " 2 2 2 2 2 3 0 3 0 2 2 4 4 3 1 3 4 0 0 3 4 2 2 3 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<175x3558 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9620 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training baseline classifier\n"
     ]
    }
   ],
   "source": [
    "# # Train Models\n",
    "# ### Baseline Model\n",
    "# “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "print(\"\\n\\nTraining baseline classifier\")\n",
    "dc = DummyClassifier(strategy=\"stratified\")\n",
    "dc.fit(Xtr, Ytr)\n",
    "\n",
    "dc_pred = dc.predict(Xde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.00      0.00      0.00         4\n",
      "                   Layoffs       0.00      0.00      0.00         6\n",
      "Major Loss for the Company       0.33      0.50      0.40         2\n",
      " Regulatory or Legal Issue       0.00      0.00      0.00         6\n",
      "                    others       0.33      0.50      0.40         2\n",
      "\n",
      "                  accuracy                           0.16       707\n",
      "                 macro avg       0.15      0.22      0.18       707\n",
      "              weighted avg       0.11      0.15      0.12       707\n",
      "\n",
      "Accuracy achieved is 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Yde, dc_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(dc_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision tree\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.67      1.00      0.80         4\n",
      "                   Layoffs       0.40      0.33      0.36         6\n",
      "Major Loss for the Company       0.67      1.00      0.80         2\n",
      " Regulatory or Legal Issue       0.40      0.33      0.36         6\n",
      "                    others       0.67      1.00      0.80         2\n",
      "\n",
      "                  accuracy                           0.49       707\n",
      "                 macro avg       0.47      0.56      0.50       707\n",
      "              weighted avg       0.45      0.49      0.46       707\n",
      "\n",
      "Accuracy achieved is 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Decision Tree\n",
    "print(\"Training Decision tree\")\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(Xtr, Ytr)\n",
    "dt_pred = dt.predict(Xde)\n",
    "print(classification_report(Yde, dt_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(dt_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       1.00      0.50      0.67         4\n",
      "                   Layoffs       0.46      1.00      0.63         6\n",
      "Major Loss for the Company       1.00      1.00      1.00         2\n",
      " Regulatory or Legal Issue       0.46      1.00      0.63         6\n",
      "                    others       1.00      1.00      1.00         2\n",
      "\n",
      "                  accuracy                           0.62       707\n",
      "                 macro avg       0.65      0.66      0.61       707\n",
      "              weighted avg       0.61      0.67      0.58       707\n",
      "\n",
      "Accuracy achieved is 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ### Random Forest\n",
    "print(\"Training Random Forest\")\n",
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(Xtr, Ytr)\n",
    "pred = rf.predict(Xde)\n",
    "print(classification_report(Yde, pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multinomial Naive Bayesian\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.57      1.00      0.73         4\n",
      "                   Layoffs       1.00      0.67      0.80         6\n",
      "Major Loss for the Company       1.00      1.00      1.00         2\n",
      " Regulatory or Legal Issue       1.00      0.67      0.80         6\n",
      "                    others       1.00      1.00      1.00         2\n",
      "\n",
      "                  accuracy                           0.73       707\n",
      "                 macro avg       0.79      0.74      0.75       707\n",
      "              weighted avg       0.81      0.70      0.73       707\n",
      "\n",
      "Accuracy achieved is 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Multinomial Naive Bayesian\n",
    "print(\"Training Multinomial Naive Bayesian\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Xtr, Ytr)\n",
    "pred_nb = nb.predict(Xde)\n",
    "print(classification_report(Yde, pred_nb, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_nb == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Support Vector Classification\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.00      0.00      0.00         4\n",
      "                   Layoffs       0.35      1.00      0.52         6\n",
      "Major Loss for the Company       0.67      1.00      0.80         2\n",
      " Regulatory or Legal Issue       0.35      1.00      0.52         6\n",
      "                    others       0.67      1.00      0.80         2\n",
      "\n",
      "                  accuracy                           0.44       707\n",
      "                 macro avg       0.26      0.51      0.34       707\n",
      "              weighted avg       0.22      0.50      0.29       707\n",
      "\n",
      "Accuracy achieved is 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ### Support Vector Classification\n",
    "print(\"Training Support Vector Classification\")\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(Xtr, Ytr)\n",
    "svc_pred = svc.predict(Xde)\n",
    "print(classification_report(Yde, svc_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(svc_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multilayered Perceptron\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       1.00      1.00      1.00         4\n",
      "                   Layoffs       0.71      0.83      0.77         6\n",
      "Major Loss for the Company       1.00      1.00      1.00         2\n",
      " Regulatory or Legal Issue       0.71      0.83      0.77         6\n",
      "                    others       1.00      1.00      1.00         2\n",
      "\n",
      "                  accuracy                           0.76       707\n",
      "                 macro avg       0.78      0.78      0.78       707\n",
      "              weighted avg       0.76      0.76      0.76       707\n",
      "\n",
      "Accuracy achieved is 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1870: UserWarning: labels size, 175, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "# ### Multilayered Perceptron\n",
    "print(\"Training Multilayered Perceptron\")\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 20), random_state=1, max_iter=400)\n",
    "mlp.fit(Xtr, Ytr)\n",
    "mlp_pred = mlp.predict(Xde)\n",
    "print(classification_report(Yde, mlp_pred, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved is 0.15\n",
      "Accuracy achieved is 0.5\n",
      "Accuracy achieved is 0.7\n",
      "Accuracy achieved is 0.4\n",
      "Accuracy achieved is 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy achieved is ' + str(np.mean(dc_pred   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(dt_pred   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_nb   == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(svc_pred  == Yde)))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred  == Yde)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predicting test data using Multilayered Perceptron\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       1.00      0.60      0.75         5\n",
      "                   Layoffs       0.38      0.75      0.50         4\n",
      "Major Loss for the Company       1.00      0.83      0.91         6\n",
      " Regulatory or Legal Issue       0.38      0.75      0.50         4\n",
      "                    others       1.00      0.83      0.91         6\n",
      "\n",
      "                  accuracy                           0.56       816\n",
      "                 macro avg       0.54      0.52      0.50       816\n",
      "              weighted avg       0.63      0.57      0.57       816\n",
      "\n",
      "Accuracy achieved is 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "# # Final Model: Multilayered Perceptron\n",
    "# ## Predict test data\n",
    "print(\"\\n\\nPredicting test data using Multilayered Perceptron\")\n",
    "pred_final = mlp.predict(Xte)\n",
    "print(classification_report(Yte, pred_final, labels=Ytr ,target_names=encoder.classes_))\n",
    "print('Accuracy achieved is ' + str(accuracy_score(Yte,pred_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\"title\":vectorizer.inverse_transform(Xte), \"predicted\":encoder.inverse_transform(pred_final),\"actual\": encoder.inverse_transform(Yte)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(output, columns=[\"title\",\"predicted\",\"actual\"])\n",
    "#df.to_csv(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\News333_title_predication_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved is 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "pred_final = mlp.predict(Xte)\n",
    "print('Accuracy achieved is ' + str(np.mean(pred_final == Yte)))\n",
    "output = {\"text\":vectorizer.inverse_transform(Xte), \"predicted\":encoder.inverse_transform(pred_final),\"actual\": encoder.inverse_transform(Yte)}\n",
    "df = pd.DataFrame(output, columns=[\"text\",\"predicted\",\"actual\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output, columns=[\"text\",\"predicted\",\"actual\"])\n",
    "df.to_csv(\"C:\\\\Users\\\\Kratika\\\\Downloads\\\\old.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#GET VECTOR COUNT\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(news.clean_text)\n",
    "\n",
    "#SAVE WORD VECTOR\n",
    "pickle.dump(count_vect.vocabulary_, open(\"count_vector.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#TRANSFORM WORD VECTOR TO TF IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#SAVE TF-IDF\n",
    "pickle.dump(tfidf_transformer, open(\"tfidf.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#mlp =       MLPClassifier(solver='adam',  alpha=1e-5, hidden_layer_sizes=(100, 20), random_state=1, max_iter=400)\n",
    "clf_neural = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, news.important, test_size=0.25, random_state=42)\n",
    "\n",
    "clf_neural.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.67      0.50      0.57         8\n",
      "                   Layoffs       0.67      0.89      0.76         9\n",
      "Major Loss for the Company       0.92      0.92      0.92        13\n",
      " Regulatory or Legal Issue       1.00      0.56      0.72        16\n",
      "                    others       0.33      0.56      0.42         9\n",
      "\n",
      "                  accuracy                           0.69        55\n",
      "                 macro avg       0.72      0.69      0.68        55\n",
      "              weighted avg       0.77      0.69      0.70        55\n",
      "\n",
      "Accuracy achieved is 0.6909090909090909\n"
     ]
    }
   ],
   "source": [
    "predicted = clf_neural.predict(X_test)\n",
    "print(classification_report(y_test, predicted))\n",
    "print('Accuracy achieved is ' + str(np.mean(predicted == y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.33      0.12      0.18         8\n",
      "                   Layoffs       0.89      0.89      0.89         9\n",
      "Major Loss for the Company       0.87      1.00      0.93        13\n",
      " Regulatory or Legal Issue       0.67      0.62      0.65        16\n",
      "                    others       0.23      0.33      0.27         9\n",
      "\n",
      "                  accuracy                           0.64        55\n",
      "                 macro avg       0.60      0.59      0.58        55\n",
      "              weighted avg       0.63      0.64      0.62        55\n",
      "\n",
      "Accuracy achieved is 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 20), random_state=1, max_iter=400)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "       Financial Challenge       0.50      0.38      0.43         8\n",
      "                   Layoffs       0.89      0.89      0.89         9\n",
      "Major Loss for the Company       0.76      1.00      0.87        13\n",
      " Regulatory or Legal Issue       0.71      0.62      0.67        16\n",
      "                    others       0.11      0.11      0.11         9\n",
      "\n",
      "                  accuracy                           0.64        55\n",
      "                 macro avg       0.60      0.60      0.59        55\n",
      "              weighted avg       0.62      0.64      0.62        55\n",
      "\n",
      "Accuracy achieved is 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100,), activation='relu', random_state=1, max_iter=400)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)  \n",
    "print(classification_report(y_test, mlp_pred))\n",
    "print('Accuracy achieved is ' + str(np.mean(mlp_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
